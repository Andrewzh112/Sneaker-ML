{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import shutil\n",
    "from utils import train_test_names\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyped_info_df = pd.read_csv(os.path.join('..','data','hyped_info_df.csv'),index_col=0)\n",
    "non_hyped_info_df = pd.read_csv(os.path.join('..','data','non_hyped_info_df.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split for hyped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting train and and test for hyped shoes. Grouped by similar names\n",
    "hyped_info_df = hyped_info_df.set_index('name')\n",
    "hypetrain, hypetest = train_test_names(hyped_info_df.index.tolist(),test_size=0.1,seed=24)\n",
    "hyped_info_df['hypetrain'] = 1\n",
    "for t in hypetest:\n",
    "    hyped_info_df.loc[t,'hypetrain'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004462753175421"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "hyped_info_df.hypetrain.sum() / hyped_info_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easier split for nonhyped\n",
    "n_test = int(non_hyped_info_df.shape[0]*0.1)\n",
    "non_hyped_names = non_hyped_info_df.index.tolist()\n",
    "np.random.shuffle(non_hyped_names)\n",
    "train_non_hyped_names = non_hyped_names[n_test:]\n",
    "test_non_hyped_names = non_hyped_names[:n_test]\n",
    "\n",
    "non_hyped_info_df['hypetrain'] = 1\n",
    "for t in test_non_hyped_names:\n",
    "    non_hyped_info_df.loc[t,'hypetrain'] = 0\n",
    "non_hyped_info_df.loc['special','hypetrain'] = 0 # I want this image to be in test set \n",
    "non_hyped_info_df = non_hyped_info_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split for Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyped_info_df[~hyped_info_df.brand.isin(['nike','jordan','adidas'])].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_brands = ['nike','jordan','adidas']\n",
    "hyped_info_df['classification_brands'] = hyped_info_df['brand'].apply(lambda brand: 'other' if brand not in main_brands else brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_brands = hyped_info_df.classification_brands.unique()\n",
    "hyped_info_df['brandtrain'] = 1\n",
    "for brand in classification_brands:\n",
    "    brand_sub = hyped_info_df[hyped_info_df.classification_brands==brand]\n",
    "    brandtrain, brandtest = train_test_names(brand_sub.index)\n",
    "    for t in brandtest:\n",
    "        hyped_info_df.loc[t,'brandtrain'] = 0\n",
    "hyped_info_df = hyped_info_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004462753175421"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyped_info_df.brandtrain.sum() / hyped_info_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make new directories and copy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new meta df\n",
    "# hyped_info_df.to_csv(os.path.join(os.getcwd(),'..','data','hyped_info_df.csv'),index=False)\n",
    "# non_hyped_info_df.to_csv(os.path.join(os.getcwd(),'..','data','non_hyped_info_df.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_image_copy(row,train_path,test_path,task):\n",
    "    image = Image.open(row['path'])\n",
    "    ext = re.search(r'(.jpg|.png)',row['path']).group()\n",
    "    if row[task]==1:\n",
    "        image.save(os.path.join(train_path,str(row['name'])+str(row['source'])+str(row.name)+str(ext)))\n",
    "    else:\n",
    "        image.save(os.path.join(test_path,str(row['name'])+str(row['source'])+str(row.name)+str(ext)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_folders = ['brand_data','hype_data']\n",
    "for folder in train_test_folders:\n",
    "    path = os.path.join(os.getcwd(),'..','data',folder)\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "hype_path = os.path.join(os.getcwd(),'..','data','hype_data')\n",
    "brand_path = os.path.join(os.getcwd(),'..','data','brand_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for brand in hyped_info_df.classification_brands.unique():\n",
    "    train_path = os.path.join(brand_path,'train',brand)\n",
    "    test_path = os.path.join(brand_path,'test',brand)\n",
    "    for path in [train_path,test_path]:\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "        os.makedirs(path)\n",
    "    subset_df = hyped_info_df[hyped_info_df.classification_brands==brand]\n",
    "    subset_df.apply(lambda row: train_test_image_copy(row,train_path,test_path,'brandtrain'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ishype in ['hype','non_hype']:\n",
    "    train_path = os.path.join(hype_path,'train',ishype)\n",
    "    test_path = os.path.join(hype_path,'test',ishype)\n",
    "    for path in [train_path,test_path]:\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "        os.makedirs(path)\n",
    "    if ishype == 'hype':\n",
    "        hyped_info_df.apply(lambda row: train_test_image_copy(row,train_path,test_path,'hypetrain'),axis=1)\n",
    "    else:\n",
    "        non_hyped_info_df.apply(lambda row: train_test_image_copy(row,train_path,test_path,'hypetrain'),axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
