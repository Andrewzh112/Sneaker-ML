{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8EPs6uIzS3Vz",
    "outputId": "a3d1e18f-6292-441c-bad2-5ce594544d1a"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Activation, BatchNormalization, Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.util import montage\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UHoUa6LS3V5"
   },
   "outputs": [],
   "source": [
    "img_rows = 224\n",
    "img_cols = 224\n",
    "channels = 3\n",
    "\n",
    "# Input image dimensions\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "# Size of the noise vector, used as input to the Generator\n",
    "z_dim = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jv9iX9YPS3V8"
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgcXyP-OS3V8"
   },
   "outputs": [],
   "source": [
    "def build_generator(z_dim):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Reshape input into 7x7x256 tensor via a fully connected layer\n",
    "    model.add(Dense(256 * 7 * 7, input_dim=z_dim))\n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "\n",
    "    # Transposed convolution layer, from 7x7x256 into 14x14x128 tensor\n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Transposed convolution layer, from 14x14x128 to 14x14x64 tensor\n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Transposed convolution layer, from 14x14x64 to 28x28x32 tensor\n",
    "    model.add(Conv2DTranspose(32, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Transposed convolution layer, from 28x28x32 to 56x56x16 tensor\n",
    "    model.add(Conv2DTranspose(16, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Transposed convolution layer, from 56x56x16 to 112x112x8 tensor\n",
    "    model.add(Conv2DTranspose(8, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Transposed convolution layer, from 112x112x8 to 224x224x3 tensor\n",
    "    model.add(Conv2DTranspose(3, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # Output layer with tanh activation\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LbMpR7ExS3V-"
   },
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7O4ojJ6vS3V_"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional layer, from 28x28x1 into 14x14x32 tensor\n",
    "    model.add(\n",
    "        Conv2D(32,\n",
    "            kernel_size=3,\n",
    "            strides=2,\n",
    "            input_shape=img_shape,\n",
    "            padding='same'))\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Convolutional layer, from 14x14x32 into 7x7x64 tensor\n",
    "    model.add(\n",
    "        Conv2D(64,\n",
    "            kernel_size=3,\n",
    "            strides=2,\n",
    "            input_shape=img_shape,\n",
    "            padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Convolutional layer, from 7x7x64 tensor into 3x3x128 tensor\n",
    "    model.add(\n",
    "        Conv2D(128,\n",
    "          kernel_size=3,\n",
    "          strides=2,\n",
    "          input_shape=img_shape,\n",
    "          padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(256,\n",
    "          kernel_size=3,\n",
    "          strides=2,\n",
    "          input_shape=img_shape,\n",
    "          padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(512,\n",
    "          kernel_size=3,\n",
    "          strides=2,\n",
    "          input_shape=img_shape,\n",
    "          padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(1028,\n",
    "          kernel_size=3,\n",
    "          strides=2,\n",
    "          input_shape=img_shape,\n",
    "          padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Output layer with sigmoid activation\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X3r3Ef9vS3WC"
   },
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6Q9z89VS3WD"
   },
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Combined Generator -> Discriminator model\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M690pqToS3WH"
   },
   "outputs": [],
   "source": [
    "# Build and compile the Discriminator\n",
    "discriminator = build_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Build the Generator\n",
    "generator = build_generator(z_dim)\n",
    "\n",
    "# Keep Discriminatorâ€™s parameters constant for Generator training\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Build and compile GAN model with fixed Discriminator to train the Generator\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5SJ6Ha4S3WJ"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUP-AuriS3WK"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "iteration_checkpoints = []\n",
    "\n",
    "\n",
    "def train(iterations, batch_size, sample_interval):\n",
    "\n",
    "    \n",
    "    X_train = [np.asarray(Image.open(img)) for img in glob(os.path.join('..','data','all_hyped','**'))]\n",
    "    X_train = np.stack(X_train)\n",
    "\n",
    "    # Rescale [0, 255] pixel values to [-1, 1]\n",
    "    X_train = np.stack(X_train) / 127.5 - 1.0\n",
    "\n",
    "    # Labels for real images: all ones\n",
    "    real = np.ones((batch_size, 1))\n",
    "\n",
    "    # Labels for fake images: all zeros\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "\n",
    "        # -------------------------\n",
    "        #  Train the Discriminator\n",
    "        # -------------------------\n",
    "\n",
    "        # Get a random batch of real images\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Generate a batch of fake images\n",
    "        z = np.random.normal(0, 1, (batch_size, 500))\n",
    "        gen_imgs = generator.predict(z)\n",
    "\n",
    "        # Train Discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, real)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train the Generator\n",
    "        # ---------------------\n",
    "\n",
    "        # Generate a batch of fake images\n",
    "        z = np.random.normal(0, 1, (batch_size, 500))\n",
    "        gen_imgs = generator.predict(z)\n",
    "        # Train Generator\n",
    "        g_loss = gan.train_on_batch(z, real)\n",
    "        if (iteration + 1) % sample_interval == 0:\n",
    "\n",
    "            # Save losses and accuracies so they can be plotted after training\n",
    "            losses.append((d_loss, g_loss))\n",
    "            accuracies.append(100.0 * accuracy)\n",
    "            iteration_checkpoints.append(iteration + 1)\n",
    "\n",
    "            # Output training progress\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
    "                  (iteration + 1, d_loss, 100.0 * accuracy, g_loss))\n",
    "\n",
    "            # Output a sample of generated image\n",
    "            sample_images(generator,iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKmO0WwjS3WM"
   },
   "outputs": [],
   "source": [
    "def sample_images(generator, iteration, image_grid_rows=4, image_grid_columns=4):\n",
    "\n",
    "    # Sample random noise\n",
    "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
    "\n",
    "    # Generate images from random noise\n",
    "    gen_imgs = generator.predict(z)\n",
    "\n",
    "    # Rescale image pixel values to [0, 1]\n",
    "    gen_imgs = (0.5 * gen_imgs + 0.5) * 255\n",
    "\n",
    "    # Set image grid\n",
    "    gan_montage = montage(gen_imgs.astype(np.uint8), multichannel=True)\n",
    "    plt.imshow(gan_montage)\n",
    "    plt.axis('off')\n",
    "    gan_montage = Image.fromarray(gan_montage)\n",
    "    gan_montage.save(f'/content/outputs/montage{iteration+1}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "05rfczW6S3WO"
   },
   "source": [
    "## Train the Model and Inspect Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oesnm-DS3WO"
   },
   "source": [
    "Note that the `'Discrepancy between trainable weights and collected trainable'` warning from Keras is expected. It is by design: The Generator's trainable parameters are intentionally held constant during Discriminator training, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "sAlJpICNS3WP",
    "outputId": "ba18e4c7-c799-445e-eff3-0ad892875738"
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "iterations = 20000\n",
    "batch_size = 128\n",
    "sample_interval = 10\n",
    "\n",
    "# Train the DCGAN for the specified number of iterations\n",
    "ty = train(iterations, batch_size, sample_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-t27gQwS3WR"
   },
   "outputs": [],
   "source": [
    "losses = np.array(losses)\n",
    "\n",
    "# Plot training losses for Discriminator and Generator\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(iteration_checkpoints, losses.T[0], label=\"Discriminator loss\")\n",
    "plt.plot(iteration_checkpoints, losses.T[1], label=\"Generator loss\")\n",
    "\n",
    "plt.xticks(iteration_checkpoints, rotation=90)\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wO-lhqGvS3WT"
   },
   "outputs": [],
   "source": [
    "accuracies = np.array(accuracies)\n",
    "\n",
    "# Plot Discriminator accuracy\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(iteration_checkpoints, accuracies, label=\"Discriminator accuracy\")\n",
    "\n",
    "plt.xticks(iteration_checkpoints, rotation=90)\n",
    "plt.yticks(range(0, 100, 5))\n",
    "\n",
    "plt.title(\"Discriminator Accuracy\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73_wxeX7sKan"
   },
   "outputs": [],
   "source": [
    "!zip -r /content/outputs.zip /content/outputs\n",
    "from google.colab import files\n",
    "files.download(\"/content/outputs.zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Chapter_4_DCGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
